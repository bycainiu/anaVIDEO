"""
Bç«™ä¸‹è½½APIæœåŠ¡
ä½¿ç”¨FastAPIæä¾›RESTful APIæ¥å£
"""
import asyncio
import json
import uuid
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
from concurrent.futures import ThreadPoolExecutor

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response, HTMLResponse
from pydantic import BaseModel
import httpx
from bs4 import BeautifulSoup

from urllib.parse import urlparse

# å¯¼å…¥æˆ‘ä»¬çš„bili23_core
from bili23_core import BiliParser, BiliDownloader, BiliConfig


# å¯é€‰ä¾èµ–ï¼šyt_dlp ç”¨äºå¤šç«™ç‚¹è§£æ/ä¸‹è½½
try:
    import yt_dlp  # type: ignore
    HAS_YT_DLP = True
except Exception:
    yt_dlp = None
    HAS_YT_DLP = False

# å¯¼å…¥ç«™ç‚¹æ£€æµ‹å™¨
from site_detector import SiteDetector


# URL è¾…åŠ©åˆ¤æ–­
def is_bilibili_url(url: str) -> bool:
    try:
        host = urlparse(url).netloc.lower()
        return 'bilibili.com' in host or 'b23.tv' in host
    except Exception:
        return False


def map_qn_to_ytdlp_format(qn: Optional[int]) -> str:
    """å°†Bç«™æ¸…æ™°åº¦QNæ˜ å°„ä¸º yt-dlp çš„ format é€‰æ‹©å™¨ã€‚"""
    if not qn:
        return 'bv*+ba/best'
    mapping = {
        120: 2160,
        116: 1440,  # 1080P60/é«˜ç ç‡ï¼Œæ”¾å®½åˆ°1440ä»¥æ‹¿åˆ°æ›´é«˜æ¸…
        112: 1080,
        80: 1080,
        64: 720,
        32: 480,
        16: 360,
    }
    h = mapping.get(qn, 1080)
    # ä¼˜å…ˆ mp4 å®¹å™¨ï¼Œå›é€€ best
    return f'bv*[height<={h}][ext=mp4]+ba[ext=m4a]/b[height<={h}][ext=mp4]/best'

# æ•°æ®æ¨¡å‹
class LoginRequest(BaseModel):
    cookies: Dict[str, str]


class ParseRequest(BaseModel):
    url: str


class DownloadRequest(BaseModel):
    url: str
    quality: Optional[int] = 80  # é»˜è®¤1080P
    output_dir: Optional[str] = "./downloads"
    filename: Optional[str] = None


class TaskResponse(BaseModel):
    task_id: str
    status: str
    message: Optional[str] = None


class VideoInfo(BaseModel):
    bvid: str
    title: str
    duration: int
    owner: Dict
    pic: Optional[str] = None  # å°é¢å›¾
    quality_options: List[Dict]


# å…¨å±€å˜é‡
app = FastAPI(title="Bili23 Download API", version="1.0.0")
download_tasks = {}  # ä»»åŠ¡çŠ¶æ€ç®¡ç†
active_connections = []  # WebSocketè¿æ¥ç®¡ç†
main_loop = None  # ä¸»äº‹ä»¶å¾ªç¯
upload_executor = ThreadPoolExecutor(max_workers=3, thread_name_prefix="upload")  # ä¸Šä¼ çº¿ç¨‹æ± 
download_processes = {}  # å­˜å‚¨ä¸‹è½½è¿›ç¨‹ï¼Œç”¨äºæ‰‹åŠ¨åœæ­¢

# CORSè®¾ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ConnectionManager:
    """WebSocketè¿æ¥ç®¡ç†å™¨"""

    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)

    async def broadcast(self, message: dict):
        for connection in self.active_connections:
            try:
                await connection.send_text(json.dumps(message))
            except:
                # è¿æ¥å·²æ–­å¼€ï¼Œç§»é™¤
                self.active_connections.remove(connection)


manager = ConnectionManager()


async def check_existing_video(bvid: str) -> Optional[dict]:
    """æ£€æŸ¥BVIDæ˜¯å¦å·²å­˜åœ¨äºæ•°æ®åº“"""
    try:
        import requests

        print(f"[ç§’ä¼ æ£€æµ‹] æŸ¥è¯¢BVID: {bvid}")

        # è°ƒç”¨ExpressæœåŠ¡å™¨çš„æŸ¥è¯¢API
        response = requests.get(
            f"http://localhost:3004/api/videos/check-bilibili/{bvid}",
            timeout=5
        )

        print(f"[ç§’ä¼ æ£€æµ‹] å“åº”çŠ¶æ€: {response.status_code}")

        if response.status_code == 200:
            result = response.json()
            print(f"[ç§’ä¼ æ£€æµ‹] å“åº”æ•°æ®: {result}")

            if result.get('exists'):
                print(f"[ç§’ä¼ æ£€æµ‹] âœ… æ‰¾åˆ°å·²å­˜åœ¨çš„è§†é¢‘: {result.get('video')}")
                return result.get('video')
            else:
                print(f"[ç§’ä¼ æ£€æµ‹] âŒ è§†é¢‘ä¸å­˜åœ¨ï¼Œéœ€è¦ä¸‹è½½")

        return None

    except Exception as e:
        print(f"[ç§’ä¼ æ£€æµ‹] â— æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        return None


def progress_callback(task_id: str, progress_data: dict):
    """ä¸‹è½½è¿›åº¦å›è°ƒï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    try:
        download_tasks[task_id]["progress"] = progress_data
        download_tasks[task_id]["last_update"] = datetime.now()

        # ä½¿ç”¨ä¿å­˜çš„ä¸»å¾ªç¯è¿›è¡ŒWebSocketå¹¿æ’­
        if main_loop and not main_loop.is_closed():
            asyncio.run_coroutine_threadsafe(
                manager.broadcast({
                    "type": "progress",
                    "task_id": task_id,
                    "data": progress_data
                }),
                main_loop
            )
    except Exception as e:
        # é™é»˜å¤±è´¥ï¼Œä¸å½±å“ä¸‹è½½
        print(f"è¿›åº¦å›è°ƒé”™è¯¯: {e}")


@app.post("/api/bili/login")
async def login(request: LoginRequest) -> dict:
    """è®¾ç½®Bç«™ç™»å½•Cookie"""
    try:
        print(f"\n=== ç™»å½•è¯·æ±‚ ===")
        print(f"Cookieé”®: {list(request.cookies.keys())}")

        BiliConfig.set_cookies(request.cookies)

        # éªŒè¯Cookieæœ‰æ•ˆæ€§
        if not BiliConfig.validate_cookies():
            print(f"CookieéªŒè¯å¤±è´¥: SESSDATA={BiliConfig.User.SESSDATA[:20] if BiliConfig.User.SESSDATA else 'empty'}, DedeUserID={BiliConfig.User.DedeUserID}")
            raise HTTPException(status_code=400, detail="Cookieæ— æ•ˆæˆ–ä¸å®Œæ•´")

        print(f"ç™»å½•æˆåŠŸ! DedeUserID={BiliConfig.User.DedeUserID}\n")

        return {
            "success": True,
            "message": "ç™»å½•æˆåŠŸ",
            "user_id": BiliConfig.User.DedeUserID
        }

    except HTTPException:
        raise
    except Exception as e:
        print(f"ç™»å½•å¼‚å¸¸: {e}")
        raise HTTPException(status_code=500, detail=f"ç™»å½•å¤±è´¥: {str(e)}")


@app.post("/api/bili/parse")
async def parse_video(request: ParseRequest):
    """è§£æBç«™è§†é¢‘ä¿¡æ¯ï¼ˆæ”¯æŒå•è§†é¢‘/ç©ºé—´/ç•ªå‰§ï¼‰"""
    try:
        # éªŒè¯ç™»å½•çŠ¶æ€
        if not BiliConfig.validate_cookies():
            print(f"\n=== è§£æè¯·æ±‚è¢«æ‹’ç» ===")
            print(f"SESSDATA: {BiliConfig.User.SESSDATA[:20] if BiliConfig.User.SESSDATA else 'empty'}...")
            print(f"DedeUserID: {BiliConfig.User.DedeUserID}")
            print(f"validate_cookies(): {BiliConfig.validate_cookies()}\n")
            raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•Bç«™è´¦å·")

        print(f"\nå¼€å§‹è§£æURL: {request.url}")
        parser = BiliParser()
        video_info = parser.parse_url(request.url)

        # æ£€æŸ¥è¿”å›ç±»å‹
        if isinstance(video_info, dict):
            result_type = video_info.get('type')

            # å¦‚æœæ˜¯ç”¨æˆ·ç©ºé—´æˆ–ç•ªå‰§åˆ—è¡¨ï¼Œç›´æ¥è¿”å›
            if result_type in ['space', 'bangumi']:
                print(f"è§£æç»“æœ: {result_type}, å…± {video_info.get('total', 0)} ä¸ªè§†é¢‘")
                return video_info

        # å•ä¸ªè§†é¢‘ï¼Œè·å–ç”»è´¨é€‰é¡¹
        print(f"è§†é¢‘ä¿¡æ¯è·å–æˆåŠŸ: {video_info.get('title', 'Unknown')}")
        print(f"å°é¢å›¾: {video_info.get('pic', 'No pic')}")
        print(f"è·å–ç”»è´¨é€‰é¡¹: BVID={video_info['bvid']}, CID={video_info['cid']}")
        quality_options = parser.get_quality_options(
            video_info["bvid"],
            video_info["cid"]
        )
        print(f"ç”»è´¨é€‰é¡¹è·å–æˆåŠŸï¼Œå…± {len(quality_options)} ä¸ª")

        return VideoInfo(
            bvid=video_info["bvid"],
            title=video_info["title"],
            duration=video_info["duration"],
            owner=video_info["owner"],
            pic=video_info.get("pic"),  # å°é¢å›¾
            quality_options=quality_options
        )

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        error_detail = f"è§£æå¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_detail)
        raise HTTPException(status_code=500, detail=error_detail)


@app.post("/api/bili/download")
async def start_download(request: DownloadRequest) -> TaskResponse:
    """å¼€å§‹ä¸‹è½½è§†é¢‘"""
    try:
        # éªŒè¯ç™»å½•çŠ¶æ€
        if not BiliConfig.validate_cookies():
            raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•Bç«™è´¦å·")

        # ç”Ÿæˆä»»åŠ¡ID
        task_id = str(uuid.uuid4())

        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        download_tasks[task_id] = {
            "status": "queued",
            "url": request.url,
            "quality": request.quality,
            "output_dir": request.output_dir,
            "filename": request.filename,
            "progress": {},
            "created_at": datetime.now(),
            "last_update": datetime.now()
        }

        # ä½¿ç”¨asyncio.create_taskå¯åŠ¨å¼‚æ­¥ä»»åŠ¡
        asyncio.create_task(download_video_task(
            task_id,
            request.url,
            request.quality,
            request.output_dir,
            request.filename
        ))

        return TaskResponse(
            task_id=task_id,
            status="queued",
            message="ä¸‹è½½ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—"
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºä¸‹è½½ä»»åŠ¡å¤±è´¥: {str(e)}")


class BatchDownloadRequest(BaseModel):
    bvids: List[str]
    quality: Optional[int] = 80
    output_dir: Optional[str] = "./downloads"


@app.post("/api/bili/batch-download")
async def start_batch_download(request: BatchDownloadRequest) -> dict:
    """æ‰¹é‡ä¸‹è½½è§†é¢‘"""
    try:
        # éªŒè¯ç™»å½•çŠ¶æ€
        if not BiliConfig.validate_cookies():
            raise HTTPException(status_code=401, detail="è¯·å…ˆç™»å½•Bç«™è´¦å·")

        task_ids = []

        for bvid in request.bvids:
            task_id = str(uuid.uuid4())
            url = f"https://www.bilibili.com/video/{bvid}"

            download_tasks[task_id] = {
                "status": "queued",
                "url": url,
                "quality": request.quality,
                "output_dir": request.output_dir,
                "filename": None,
                "progress": {},
                "created_at": datetime.now(),
                "last_update": datetime.now()
            }

            # å¯åŠ¨ä¸‹è½½ä»»åŠ¡
            asyncio.create_task(download_video_task(
                task_id,
                url,
                request.quality,
                request.output_dir,
                None
            ))

            task_ids.append(task_id)

        return {
            "success": True,
            "task_ids": task_ids,
            "total": len(task_ids),
            "message": f"å·²åˆ›å»º {len(task_ids)} ä¸ªä¸‹è½½ä»»åŠ¡"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡ä¸‹è½½å¤±è´¥: {str(e)}")


@app.get("/api/bili/status/{task_id}")
async def get_download_status(task_id: str) -> dict:
    """è·å–ä¸‹è½½ä»»åŠ¡çŠ¶æ€"""
    if task_id not in download_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    task = download_tasks[task_id]
    return {
        "task_id": task_id,
        "status": task["status"],
        "progress": task.get("progress", {}),
        "created_at": task["created_at"].isoformat(),
        "last_update": task["last_update"].isoformat()
    }


@app.get("/api/bili/tasks")
async def get_all_tasks() -> dict:
    """è·å–æ‰€æœ‰ä»»åŠ¡çŠ¶æ€"""
    return {
        "tasks": [
            {
                "task_id": task_id,
                "status": task["status"],
                "url": task["url"],
                "progress": task.get("progress", {}),
                "result": task.get("result"),  # æ·»åŠ resultå­—æ®µ
                "created_at": task["created_at"].isoformat()
            }
            for task_id, task in download_tasks.items()
        ]
    }


# ===== é€šç”¨ï¼ˆå¤šç«™ç‚¹ï¼‰ä¸‹è½½ï¼šä½¿ç”¨ yt-dlp =====
class UniversalDownloadRequest(BaseModel):
    url: str
    output_dir: Optional[str] = "./downloads"
    format: Optional[str] = None  # yt-dlp æ ¼å¼é€‰æ‹©è¡¨è¾¾å¼ï¼Œå¯é€‰


@app.post("/api/universal/parse")
async def universal_parse_video(request: ParseRequest) -> dict:
    """
    é€šç”¨è§†é¢‘è§£æï¼ˆæ”¯æŒå¤šç«™ç‚¹ï¼‰
    è¿”å›ä¸Bç«™å…¼å®¹çš„æ ¼å¼
    """
    if not HAS_YT_DLP:
        raise HTTPException(status_code=501, detail="æœåŠ¡å™¨æœªå®‰è£… yt-dlpï¼Œè¯·å…ˆå®‰è£…ï¼špip install yt-dlp")

    try:
        # æ£€æµ‹ç«™ç‚¹
        site_info = SiteDetector.detect(request.url)
        if not site_info:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„è§†é¢‘ç½‘ç«™")

        print(f"\n=== [Universal Parse] è§£æè§†é¢‘ ===")
        print(f"URL: {request.url}")
        print(f"ç«™ç‚¹: {site_info.display_name} ({site_info.name})")
        print(f"æ”¯æŒç”»è´¨é€‰æ‹©: {site_info.supports_quality}")
        print(f"ä½¿ç”¨å¼•æ“: {'yt-dlp' if site_info.use_ytdlp else 'è‡ªå®šä¹‰'}")

        # ä½¿ç”¨yt-dlpæå–ä¿¡æ¯(æ·»åŠ è¯¦ç»†æ—¥å¿—å’Œåé™åˆ¶æªæ–½)
        ydl_opts = {
            'quiet': False,  # æ”¹ä¸ºFalseä»¥æŸ¥çœ‹è¯¦ç»†è¾“å‡º
            'no_warnings': False,  # æ”¹ä¸ºFalseä»¥æŸ¥çœ‹è­¦å‘Š
            'extract_flat': False,
            'noplaylist': True,  # â­ åªä¸‹è½½å•ä¸ªè§†é¢‘,å¿½ç•¥æ’­æ”¾åˆ—è¡¨
            'socket_timeout': 30,  # 30ç§’è¶…æ—¶
            'retries': 5,  # å¢åŠ é‡è¯•æ¬¡æ•°åˆ°5æ¬¡
            'fragment_retries': 5,
            'skip_unavailable_fragments': True,
            'ignoreerrors': False,
            'no_color': True,
            'verbose': False,  # ä¸éœ€è¦è¿‡äºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            # ä¼ªè£…æˆæµè§ˆå™¨
            'http_headers': {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'en-us,en;q=0.5',
                'Sec-Fetch-Mode': 'navigate',
            },
        }
        
        # å¦‚æœæœ‰cookiesæ–‡ä»¶,ä½¿ç”¨å®ƒ(YouTubeç­‰ç«™ç‚¹éœ€è¦)
        cookies_file = Path('./cookies.txt')
        if cookies_file.exists():
            ydl_opts['cookiefile'] = str(cookies_file)
            print(f"[yt-dlp] ä½¿ç”¨cookiesæ–‡ä»¶: {cookies_file}")
        else:
            print(f"[yt-dlp] æœªæ‰¾åˆ°cookiesæ–‡ä»¶,å»ºè®®åˆ›å»º cookies.txt ä»¥é¿å…é€Ÿç‡é™åˆ¶")

        print(f"[yt-dlp] å¼€å§‹æå–è§†é¢‘ä¿¡æ¯...")
        print(f"[yt-dlp] é…ç½®: {ydl_opts}")
        
        # ç›´æ’­å¹³å°åˆ—è¡¨
        LIVE_PLATFORMS = ['huya', 'douyu', 'twitch']
        is_live_platform = site_info.name in LIVE_PLATFORMS
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                print(f"[yt-dlp] è°ƒç”¨ extract_info()...")
                info = ydl.extract_info(request.url, download=False)
                print(f"[yt-dlp] âœ… extract_info() å®Œæˆ")
                
                if not info:
                    raise Exception("yt-dlpè¿”å›äº†ç©ºçš„ä¿¡æ¯å¯¹è±¡")
                    
                print(f"[yt-dlp] è§†é¢‘ID: {info.get('id')}")
                print(f"[yt-dlp] æ ‡é¢˜: {info.get('title')}")
                print(f"[yt-dlp] æ ¼å¼æ•°é‡: {len(info.get('formats', []))}")
                
        except Exception as e:
            error_str = str(e)
            print(f"[yt-dlp] âŒ æå–ä¿¡æ¯å¤±è´¥: {error_str}")
            import traceback
            traceback_str = traceback.format_exc()
            print(f"[yt-dlp] è¯¦ç»†é”™è¯¯:\n{traceback_str}")
            
            # æ£€æµ‹æ˜¯å¦æ˜¯yt-dlpçš„Huyaæå–å™¨bug(ç¦»çº¿ç›´æ’­é—´)
            if "huya.py" in traceback_str and "'NoneType' and 'float'" in error_str:
                friendly_msg = f"âŒ {site_info.display_name}ç›´æ’­é—´å½“å‰ç¦»çº¿(æœªå¼€æ’­)\n\n"
                friendly_msg += f"ğŸ’¡ æç¤º:\n"
                friendly_msg += f"  â€¢ è¯¥ä¸»æ’­å½“å‰æœªå¼€æ’­ï¼Œæ— æ³•è·å–ç›´æ’­æµ\n"
                friendly_msg += f"  â€¢ ç›´æ’­å¹³å°åªèƒ½è§£æå’Œä¸‹è½½æ­£åœ¨ç›´æ’­çš„å†…å®¹\n"
                friendly_msg += f"  â€¢ è¯·ç­‰å¾…ä¸»æ’­å¼€æ’­åå†è¯•\n\n"
                friendly_msg += f"âš ï¸ æŠ€æœ¯è¯¦æƒ…: yt-dlpçš„è™ç‰™æå–å™¨åœ¨å¤„ç†ç¦»çº¿ç›´æ’­é—´æ—¶å­˜åœ¨bug"
                raise HTTPException(status_code=400, detail=friendly_msg)
            
            # é’ˆå¯¹ç›´æ’­å¹³å°çš„é€šç”¨é”™è¯¯æç¤º
            if is_live_platform and ('offline' in error_str.lower() or 'not available' in error_str.lower()):
                friendly_msg = f"âŒ {site_info.display_name}ç›´æ’­é—´å½“å‰ç¦»çº¿(æœªå¼€æ’­æˆ–å·²ç»“æŸ)\n\n"
                friendly_msg += f"ğŸ’¡ æç¤º:\n"
                friendly_msg += f"  â€¢ ç›´æ’­å¹³å°åªèƒ½è§£æå’Œä¸‹è½½æ­£åœ¨ç›´æ’­çš„å†…å®¹\n"
                friendly_msg += f"  â€¢ è¯·ç¡®è®¤ä¸»æ’­æ˜¯å¦æ­£åœ¨ç›´æ’­\n"
                friendly_msg += f"  â€¢ å½•æ’­/é‡æ’­å†…å®¹æš‚ä¸æ”¯æŒä¸‹è½½\n\n"
                friendly_msg += f"ğŸ”— åŸå§‹é”™è¯¯: {error_str}"
                raise HTTPException(status_code=400, detail=friendly_msg)
            
            raise
            
        print(f"[è§£æ] ä¿¡æ¯æå–å®Œæˆ,å¼€å§‹å¤„ç†...")

        # è½¬æ¢ä¸ºBç«™å…¼å®¹æ ¼å¼
        print(f"[è§£æ] å¼€å§‹æå–è§†é¢‘å±æ€§...")
        video_id = info.get('id', 'unknown')
        title = info.get('title', 'Unknown Title')
        # å®‰å…¨å¤„ç†durationï¼Œç¡®ä¿ä¸ä¸ºNone
        raw_duration = info.get('duration')
        duration = int(raw_duration) if raw_duration is not None else 0
        uploader = info.get('uploader') or info.get('channel') or 'Unknown'
        thumbnail = info.get('thumbnail')
        
        print(f"[è§£æ] è§†é¢‘å±æ€§:")
        print(f"  - ID: {video_id}")
        print(f"  - æ ‡é¢˜: {title}")
        print(f"  - æ—¶é•¿: {duration}ç§’")
        print(f"  - UPä¸»: {uploader}")
        print(f"  - å°é¢: {thumbnail[:50] if thumbnail else 'N/A'}...")

        # æå–ç”»è´¨é€‰é¡¹ï¼ˆå¦‚æœæ”¯æŒï¼‰
        quality_options = []
        print(f"[ç”»è´¨] å¼€å§‹æå–ç”»è´¨é€‰é¡¹...")
        print(f"[ç”»è´¨] ç«™ç‚¹æ”¯æŒç”»è´¨é€‰æ‹©: {site_info.supports_quality}")
        
        if site_info.supports_quality and info.get('formats'):
            formats = info['formats']
            print(f"[ç”»è´¨] æ‰¾åˆ° {len(formats)} ä¸ªæ ¼å¼")
            
            # æŒ‰é«˜åº¦åˆ†ç»„å»é‡
            height_map = {}
            for fmt in formats:
                height = fmt.get('height')
                format_id = fmt.get('format_id')
                vbr = fmt.get('vbr') or 0  # å¤„ç†Noneå€¼
                ext = fmt.get('ext')
                
                if height and height > 0:
                    # å®‰å…¨åœ°æ¯”è¾ƒvbr,å¤„ç†Noneå€¼
                    existing_vbr = height_map.get(height, {}).get('vbr') or 0
                    if height not in height_map or vbr > existing_vbr:
                        height_map[height] = fmt
                        print(f"[ç”»è´¨]   {height}P (format_id: {format_id}, vbr: {vbr}, ext: {ext})")

            print(f"[ç”»è´¨] å»é‡åæœ‰ {len(height_map)} ä¸ªç”»è´¨é€‰é¡¹")
            
            # ç”Ÿæˆç”»è´¨é€‰é¡¹
            for height in sorted(height_map.keys(), reverse=True):
                fmt = height_map[height]
                quality_options.append({
                    'quality': height,
                    'description': f'{height}P',
                    'format_id': fmt.get('format_id'),
                })
        else:
            print(f"[ç”»è´¨] ä¸æ”¯æŒç”»è´¨é€‰æ‹©æˆ–æ²¡æœ‰æ ¼å¼ä¿¡æ¯,ä½¿ç”¨é»˜è®¤ç”»è´¨")

        print(f"[æ„å»º] å¼€å§‹æ„å»ºè¿”å›ç»“æœ...")
        
        result = {
            'bvid': video_id,  # ä½¿ç”¨video_idä½œä¸ºbvid
            'title': title,
            'duration': duration,  # durationå·²ç»å®‰å…¨å¤„ç†ä¸ºint
            'owner': {'name': uploader},
            'pic': thumbnail,
            'quality_options': quality_options if quality_options else [
                {'quality': 0, 'description': 'é»˜è®¤ç”»è´¨', 'format_id': 'best'}
            ],
            'site_info': {
                'name': site_info.name,
                'display_name': site_info.display_name,
                'icon': site_info.icon,
                'color': site_info.color,
            },
        }

        print(f"\n=== [è§£ææˆåŠŸ] ===")
        print(f"âœ… æ ‡é¢˜: {title}")
        print(f"âœ… æ—¶é•¿: {duration}ç§’")
        print(f"âœ… UPä¸»: {uploader}")
        print(f"âœ… ç”»è´¨é€‰é¡¹: {len(quality_options)}ä¸ª")
        print(f"âœ… ç«™ç‚¹: {site_info.display_name}")
        print(f"==================\n")

        return result

    except Exception as e:
        import traceback
        error_msg = f"è§£æå¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_msg)
        raise HTTPException(status_code=500, detail=f"è§£æè§†é¢‘å¤±è´¥: {str(e)}")


@app.post("/api/universal/download")
async def universal_start_download(request: UniversalDownloadRequest) -> TaskResponse:
    if not HAS_YT_DLP:
        raise HTTPException(status_code=501, detail="æœåŠ¡å™¨æœªå®‰è£… yt-dlpï¼Œè¯·å…ˆå®‰è£…ï¼špip install yt-dlp")

    task_id = str(uuid.uuid4())
    download_tasks[task_id] = {
        "status": "queued",
        "url": request.url,
        "output_dir": request.output_dir,
        "progress": {},
        "created_at": datetime.now(),
        "last_update": datetime.now(),
        "source": "universal",
    }

    asyncio.create_task(universal_download_task(task_id, request.url, request.output_dir or "./downloads", request.format))

    return TaskResponse(task_id=task_id, status="queued", message="é€šç”¨ä¸‹è½½ä»»åŠ¡å·²åŠ å…¥é˜Ÿåˆ—")

@app.delete("/api/bili/tasks/{task_id}")
async def cancel_task(task_id: str) -> dict:
    """å–æ¶ˆä¸‹è½½ä»»åŠ¡"""
    if task_id not in download_tasks:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    task = download_tasks[task_id]
    if task["status"] in ["completed", "failed"]:
        del download_tasks[task_id]
        return {"message": "ä»»åŠ¡å·²åˆ é™¤"}
    else:
        # æ ‡è®°ä¸ºå–æ¶ˆçŠ¶æ€
        task["status"] = "cancelled"
        
        # å¦‚æœå­˜åœ¨ä¸‹è½½è¿›ç¨‹ï¼Œå°è¯•ç»ˆæ­¢
        if task_id in download_processes:
            ydl_instance = download_processes[task_id]
            try:
                print(f"[{task_id}] æ­£åœ¨ç»ˆæ­¢ä¸‹è½½...")  
                # å¯¹äº yt-dlpï¼Œæˆ‘ä»¬åªéœ€è®¾ç½®å–æ¶ˆæ ‡å¿—ï¼Œä¸‹è½½å¾ªç¯ä¼šæ£€æŸ¥å¹¶é€€å‡º
                # yt-dlp æœ¬èº«ä¼šåœ¨ä¸‹æ¬¡æ£€æŸ¥æ—¶åœæ­¢
                if hasattr(ydl_instance, '_stop'):
                    ydl_instance._stop = True
                del download_processes[task_id]
                print(f"[{task_id}] å·²å‘é€å–æ¶ˆä¿¡å·")
            except Exception as e:
                print(f"[{task_id}] ç»ˆæ­¢ä¸‹è½½å¤±è´¥: {e}")
        
        await manager.broadcast({"type": "status", "task_id": task_id, "status": "cancelled"})
        return {"message": "ä»»åŠ¡å·²å–æ¶ˆ"}


@app.websocket("/ws/progress")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocketè¿æ¥ç”¨äºå®æ—¶è¿›åº¦æ¨é€"""
    await manager.connect(websocket)
    try:
        while True:
            # ä¿æŒè¿æ¥æ´»è·ƒ
            await websocket.receive_text()
    except WebSocketDisconnect:
        manager.disconnect(websocket)


async def download_video_task(task_id: str, url: str, quality: int, output_dir: str, filename: str):
    """å¼‚æ­¥ä¸‹è½½ä»»åŠ¡"""
    global main_loop
    if main_loop is None:
        main_loop = asyncio.get_running_loop()

    print(f"\n=== ä¸‹è½½ä»»åŠ¡å¼€å§‹ ===")
    print(f"Task ID: {task_id}")
    print(f"URL: {url}")
    print(f"Quality: {quality}")
    print(f"Output: {output_dir}")

    try:
        # æ›´æ–°çŠ¶æ€ä¸ºè§£æä¸­
        print(f"æ›´æ–°çŠ¶æ€: parsing")
        download_tasks[task_id]["status"] = "parsing"
        await manager.broadcast({
            "type": "status",
            "task_id": task_id,
            "status": "parsing"
        })

        # è§£æè§†é¢‘ä¿¡æ¯
        print("å¼€å§‹è§£æè§†é¢‘ä¿¡æ¯...")
        parser = BiliParser()
        video_info = parser.parse_url(url)
        bvid = video_info.get('bvid')
        title = video_info.get('title', 'Unknown')
        print(f"è§†é¢‘è§£ææˆåŠŸ: {title} (BVID: {bvid})")

        # æ£€æŸ¥æ˜¯å¦å·²ç»ä¸‹è½½è¿‡
        existing_video = await check_existing_video(bvid)
        if existing_video:
            print(f"âš¡ æ£€æµ‹åˆ°å·²ä¸‹è½½è¿‡çš„è§†é¢‘: {existing_video.get('video_id')}")

            # ç›´æ¥è¿”å›å·²å­˜åœ¨çš„ç»“æœ
            download_tasks[task_id]["status"] = "completed"
            download_tasks[task_id]["result"] = {
                "from_cache": True,
                "bvid": bvid,
                "video_id": existing_video.get('video_id'),
                "title": title,
                "message": "è§†é¢‘å·²å­˜åœ¨ï¼Œç§’ä¼ å®Œæˆ"
            }
            download_tasks[task_id]["video_id"] = existing_video.get('video_id')

            await manager.broadcast({
                "type": "completed",
                "task_id": task_id,
                "result": download_tasks[task_id]["result"]
            })

            print(f"âœ… ç§’ä¼ å®Œæˆï¼Œè·³è¿‡ä¸‹è½½")
            return

        # è·å–ä¸‹è½½é“¾æ¥
        print(f"è·å–ä¸‹è½½é“¾æ¥... BVID={video_info['bvid']}, CID={video_info['cid']}, Quality={quality}")
        download_urls = parser.get_download_urls(
            video_info["bvid"],
            video_info["cid"],
            quality
        )
        print(f"ä¸‹è½½é“¾æ¥è·å–æˆåŠŸ: è§†é¢‘={len(download_urls.get('video_urls', []))}, éŸ³é¢‘={len(download_urls.get('audio_urls', []))}")

        # æ›´æ–°çŠ¶æ€ä¸ºä¸‹è½½ä¸­
        download_tasks[task_id]["status"] = "downloading"
        await manager.broadcast({
            "type": "status",
            "task_id": task_id,
            "status": "downloading"
        })

        # åˆ›å»ºä¸‹è½½å™¨
        def callback(progress_data):
            progress_callback(task_id, progress_data)

        downloader = BiliDownloader(progress_callback=callback)

        # åˆ†ç¦»è§†é¢‘å’ŒéŸ³é¢‘ä¿¡æ¯
        video_data = {
            "video_urls": download_urls.get("video_urls", []),
            "title": video_info.get("title", "video")
        }
        audio_data = {
            "audio_urls": download_urls.get("audio_urls", [])
        }

        # å¼€å§‹ä¸‹è½½
        print(f"å¼€å§‹ä¸‹è½½è§†é¢‘: {filename or video_info.get('title', 'video')}")
        result = await downloader.download_video(
            video_data,
            audio_data,
            output_dir,
            filename or video_info.get("title", "video")
        )
        print(f"ä¸‹è½½å®Œæˆ: {result}")

        # å¦‚æœæ˜¯DASHæ ¼å¼ï¼Œéœ€è¦åˆå¹¶éŸ³è§†é¢‘
        if download_urls.get("format") == "dash" and len(result["results"]) == 2:
            # æ›´æ–°çŠ¶æ€ä¸ºåˆå¹¶ä¸­
            download_tasks[task_id]["status"] = "merging"
            await manager.broadcast({
                "type": "status",
                "task_id": task_id,
                "status": "merging"
            })

            video_file = None
            audio_file = None

            for res in result["results"]:
                if res.get("file_type") == "video":
                    video_file = res.get("file_path")
                elif res.get("file_type") == "audio":
                    audio_file = res.get("file_path")

            if video_file and audio_file:
                # ä½¿ç”¨ task_id ä½œä¸ºæ–‡ä»¶åï¼Œä¿æŒä¸€è‡´æ€§
                output_file = Path(output_dir) / f"{task_id}.mp4"
                merge_success = await downloader.merge_video_audio(
                    video_file,
                    audio_file,
                    str(output_file)
                )

                if merge_success:
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    try:
                        os.remove(video_file)
                        os.remove(audio_file)
                    except:
                        pass
                    result["final_file"] = str(output_file)

        # æ·»åŠ BVIDåˆ°ç»“æœä¸­
        result["bvid"] = bvid
        result["title"] = title

        # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
        download_tasks[task_id]["status"] = "completed"
        download_tasks[task_id]["result"] = result

        await manager.broadcast({
            "type": "completed",
            "task_id": task_id,
            "result": result
        })

        # è°ƒç”¨åç»­å¤„ç†æµç¨‹
        await trigger_post_processing(task_id, result)
    except Exception as e:
        import traceback
        error_msg = f"ä¸‹è½½å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(error_msg)

        download_tasks[task_id]["status"] = "failed"
        download_tasks[task_id]["error"] = str(e)

        await manager.broadcast({
            "type": "failed",
            "task_id": task_id,
            "error": str(e)
        })



async def universal_download_task(task_id: str, url: str, output_dir: str, format_select: Optional[str]):
    """
    é€šç”¨ä¸‹è½½ä»»åŠ¡ï¼ˆåŸºäº yt-dlpï¼‰
    - è¿›åº¦é€šè¿‡ WebSocket ä¸ download_tasks åŒæ­¥ï¼Œä¿æŒä¸Bç«™ä¸‹è½½ä¸€è‡´çš„æ¶ˆæ¯æ ¼å¼
    - é»˜è®¤ä¸‹è½½æœ€ä½³ç”»è´¨å¹¶è‡ªåŠ¨åˆå¹¶ï¼ˆéœ€è¦æœ¬æœº ffmpegï¼‰
    """
    global main_loop
    if main_loop is None:
        main_loop = asyncio.get_running_loop()

    print(f"\n=== [Universal Download] ä¸‹è½½ä»»åŠ¡å¼€å§‹ ===")
    print(f"Task ID: {task_id}")
    print(f"URL: {url}")
    print(f"Output: {output_dir}")
    print(f"Format: {format_select or 'é»˜è®¤'}")

    try:
        # çŠ¶æ€ï¼šparsing
        print(f"[{task_id}] çŠ¶æ€: parsing")
        download_tasks[task_id]["status"] = "parsing"
        await manager.broadcast({"type": "status", "task_id": task_id, "status": "parsing"})

        Path(output_dir).mkdir(parents=True, exist_ok=True)
        print(f"[{task_id}] è¾“å‡ºç›®å½•å·²åˆ›å»º: {output_dir}")

        def _progress_hook(d):
            try:
                status = d.get('status')
                if status == 'downloading':
                    downloaded = d.get('downloaded_bytes') or 0
                    total = d.get('total_bytes') or d.get('total_bytes_estimate') or 0
                    speed = d.get('speed')
                    percent = (downloaded / total * 100) if total else None
                    progress = {
                        "file_type": "video",
                        "progress": round(percent, 2) if percent is not None else 0,
                        "downloaded": downloaded,
                        "total": total,
                        "speed": f"{speed/1024/1024:.2f} MB/s" if speed else None,
                    }
                    download_tasks[task_id]["progress"] = progress
                    download_tasks[task_id]["last_update"] = datetime.now()
                    
                    # è¾“å‡ºè¿›åº¦æ—¥å¿—
                    if percent is not None:
                        print(f"[{task_id}] ä¸‹è½½è¿›åº¦: {percent:.1f}% ({downloaded}/{total}) {progress['speed'] or ''}")
                    
                    # ç¡®ä¿ WebSocket å¹¿æ’­åœ¨äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œ
                    if main_loop and not main_loop.is_closed():
                        try:
                            asyncio.run_coroutine_threadsafe(
                                manager.broadcast({"type": "progress", "task_id": task_id, "data": progress}),
                                main_loop
                            )
                        except Exception as e:
                            print(f"[{task_id}] è­¦å‘Š: æ— æ³•å¹¿æ’­è¿›åº¦: {e}")
                elif status == 'finished':
                    print(f"[{task_id}] åˆ†æ®µä¸‹è½½å®Œæˆï¼Œåˆ‡æ¢åˆ°åˆå¹¶çŠ¶æ€")
                    # å•ä¸ªåˆ†æ®µå®Œæˆï¼Œåˆ‡æ¢çŠ¶æ€æç¤º
                    if main_loop and not main_loop.is_closed():
                        try:
                            asyncio.run_coroutine_threadsafe(
                                manager.broadcast({"type": "status", "task_id": task_id, "status": "merging"}),
                                main_loop
                            )
                        except Exception as e:
                            print(f"[{task_id}] è­¦å‘Š: æ— æ³•å¹¿æ’­çŠ¶æ€: {e}")
            except Exception as e:
                print(f"[{task_id}] è¿›åº¦é’©å­é”™è¯¯: {e}")

        print(f"[{task_id}] é…ç½® yt-dlp é€‰é¡¹...")
        
        # æ£€æµ‹æ˜¯å¦æ˜¯ç›´æ’­å¹³å°
        is_live_platform = any(domain in url.lower() for domain in ['huya.com', 'douyu.com', 'twitch.tv'])
        
        # åŸºç¡€HTTPå¤´
        base_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        }
        
        # è™ç‰™ç›´æ’­ç‰¹æ®Šé…ç½® - æ·»åŠ é˜²ç›—é“¾è¯·æ±‚å¤´
        is_huya = 'huya.com' in url.lower()
        if is_huya:
            base_headers.update({
                'Origin': 'https://www.huya.com',
                'Referer': 'https://www.huya.com/',
            })
            print(f"[{task_id}] æ£€æµ‹åˆ°è™ç‰™ç›´æ’­ï¼Œæ·»åŠ é˜²ç›—é“¾è¯·æ±‚å¤´: Origin & Referer")
        
        ydl_opts = {
            'outtmpl': str(Path(output_dir) / '%(title).200s-%(id)s.%(ext)s'),
            'noplaylist': True,
            'merge_output_format': 'mp4',
            'progress_hooks': [_progress_hook],
            'quiet': False,  # æ˜¾ç¤ºè¾“å‡º
            'no_warnings': False,  # æ˜¾ç¤ºè­¦å‘Š
            'retries': 10,
            'fragment_retries': 10,
            'http_headers': base_headers,
        }
        
        # è™ç‰™ç›´æ’­ç‰¹æ®Šé…ç½®ï¼šä¸ä½¿ç”¨å¤–éƒ¨ä¸‹è½½å™¨ï¼Œè®©yt-dlpåŸç”Ÿå¤„ç†é˜²ç›—é“¾
        if is_huya:
            print(f"[{task_id}] è™ç‰™ç›´æ’­ä½¿ç”¨ yt-dlp åŸç”Ÿä¸‹è½½å™¨ï¼ˆä¸ä½¿ç”¨ffmpegï¼‰")
            # å¯¹äºç›´æ’­æµï¼Œä½¿ç”¨ http_chunk ä¸‹è½½å™¨
            ydl_opts['downloader'] = 'http'
            # å¢åŠ ç¼“å†²åŒºå¤§å°ä»¥å¤„ç†ç›´æ’­æµ
            ydl_opts['http_chunk_size'] = 10485760  # 10MB chunks
            # æ·»åŠ é‡è¿é…ç½®
            ydl_opts['socket_timeout'] = 30
        
        # å¦‚æœæœ‰cookiesæ–‡ä»¶,ä½¿ç”¨å®ƒ
        cookies_file = Path('./cookies.txt')
        if cookies_file.exists():
            ydl_opts['cookiefile'] = str(cookies_file)
            print(f"[{task_id}] ä½¿ç”¨cookiesæ–‡ä»¶: {cookies_file}")
        else:
            print(f"[{task_id}] æœªæ‰¾åˆ°cookiesæ–‡ä»¶")
        if format_select:
            ydl_opts['format'] = format_select
            print(f"[{task_id}] ä½¿ç”¨è‡ªå®šä¹‰æ ¼å¼: {format_select}")
        else:
            # ä¼˜å…ˆ bestvideo+bestaudio/mp4 å…¶åå›é€€ best
            ydl_opts['format'] = 'bv*[ext=mp4][vcodec~="(avc|h264|h265|hevc|av01)"]+ba[ext=m4a]/b[ext=mp4]/best'
            print(f"[{task_id}] ä½¿ç”¨é»˜è®¤æ ¼å¼: {ydl_opts['format']}")

        print(f"[{task_id}] å¼€å§‹æå–è§†é¢‘ä¿¡æ¯...")
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            try:
                info = ydl.extract_info(url, download=False)
                print(f"[{task_id}] âœ… è§†é¢‘ä¿¡æ¯æå–æˆåŠŸ")
            except Exception as e:
                print(f"[{task_id}] âŒ æå–è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}")
                raise
                
            title = info.get('title') or 'video'
            thumb = info.get('thumbnail')
            duration = info.get('duration')
            uploader = info.get('uploader')
            
            # â­ å…³é”®ï¼šæ£€æŸ¥æå–å™¨è¿”å›çš„http_headersï¼Œå¹¶åˆå¹¶åˆ°ä¸‹è½½é…ç½®ä¸­
            extractor_headers = info.get('http_headers', {})
            if extractor_headers:
                print(f"[{task_id}] æ£€æµ‹åˆ°æå–å™¨æä¾›çš„HTTPå¤´: {list(extractor_headers.keys())}")
                # åˆå¹¶headersï¼Œæå–å™¨çš„headersä¼˜å…ˆçº§æ›´é«˜
                ydl_opts['http_headers'].update(extractor_headers)
                print(f"[{task_id}] å·²åˆå¹¶headers: {list(ydl_opts['http_headers'].keys())}")
                
                # è™ç‰™ç›´æ’­ä¸éœ€è¦é¢å¤–é…ç½®ï¼Œyt-dlpä¼šè‡ªåŠ¨ä½¿ç”¨æå–å™¨è¿”å›çš„headers
                if is_huya:
                    print(f"[{task_id}] è™ç‰™ç›´æ’­å·²åˆå¹¶é˜²ç›—é“¾headersï¼Œä½¿ç”¨åŸç”Ÿä¸‹è½½å™¨")
            
            print(f"[{task_id}] è§†é¢‘ä¿¡æ¯:")
            print(f"  - æ ‡é¢˜: {title}")
            print(f"  - UPä¸»: {uploader}")
            print(f"  - æ—¶é•¿: {duration}ç§’")

            # çŠ¶æ€ï¼šdownloading
            print(f"[{task_id}] çŠ¶æ€: downloading")
            download_tasks[task_id]["status"] = "downloading"
            await manager.broadcast({"type": "status", "task_id": task_id, "status": "downloading"})

            result_path = ydl.prepare_filename(info)
            print(f"[{task_id}] å¼€å§‹ä¸‹è½½åˆ°: {result_path}")
            
            # â­ å…³é”®ï¼šä½¿ç”¨æ›´æ–°åçš„headersé‡æ–°åˆ›å»ºYoutubeDLå®ä¾‹è¿›è¡Œä¸‹è½½
            print(f"[{task_id}] ä½¿ç”¨æ›´æ–°åheadersé‡æ–°åˆå§‹åŒ–ä¸‹è½½å™¨...")
        
        # åœ¨æ–°çš„contextä¸­ä½¿ç”¨æ›´æ–°åçš„headersè¿›è¡Œä¸‹è½½
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            try:
                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¢«å–æ¶ˆ
                if download_tasks[task_id].get("status") == "cancelled":
                    print(f"[{task_id}] ä»»åŠ¡å·²å–æ¶ˆï¼Œåœæ­¢ä¸‹è½½")
                    raise Exception("ä»»åŠ¡å·²è¢«ç”¨æˆ·å–æ¶ˆ")
                
                # å¯åŠ¨ä¸‹è½½å¹¶å­˜å‚¨yt-dlpå®ä¾‹ä¾›åç»­å–æ¶ˆä½¿ç”¨
                download_processes[task_id] = ydl
                ydl.download([url])
                
                # ä¸‹è½½å®Œæˆåç§»é™¤è¿›ç¨‹å¼•ç”¨
                if task_id in download_processes:
                    del download_processes[task_id]
                
                print(f"[{task_id}] âœ… ä¸‹è½½å®Œæˆ")
            except Exception as e:
                # æ¸…ç†è¿›ç¨‹å¼•ç”¨
                if task_id in download_processes:
                    del download_processes[task_id]
                
                print(f"[{task_id}] âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
                raise

        # å®Œæˆ
        print(f"\n[{task_id}] === ä¸‹è½½ä»»åŠ¡å®Œæˆ ===")
        print(f"[{task_id}] æ–‡ä»¶: {result_path}")
        print(f"[{task_id}] æ ‡é¢˜: {title}")
        
        download_tasks[task_id]["status"] = "completed"
        download_tasks[task_id]["result"] = {
            "final_file": result_path,
            "title": title,
            "thumbnail": thumb,
            "duration": duration,
            "uploader": uploader,
        }
        await manager.broadcast({"type": "completed", "task_id": task_id, "result": download_tasks[task_id]["result"]})

        # å¯é€‰ï¼šå¤ç”¨ç°æœ‰ä¸Šä¼ é€»è¾‘
        print(f"[{task_id}] å¼€å§‹åç»­å¤„ç†...")
        await trigger_post_processing(task_id, {
            "final_file": result_path,
            "bvid": "",
            "title": title,
        })

    except Exception as e:
        import traceback
        error_msg = f"[Universal Download] âŒ ä¸‹è½½å¤±è´¥: {str(e)}\n{traceback.format_exc()}"
        print(f"\n=== [{task_id}] ä¸‹è½½å¤±è´¥ ===")
        print(error_msg)
        print(f"==================\n")
        
        download_tasks[task_id]["status"] = "failed"
        download_tasks[task_id]["error"] = str(e)
        await manager.broadcast({"type": "failed", "task_id": task_id, "error": str(e)})





def upload_file_sync(final_file: str, task_id: str, bvid: str, title: str = None):
    """åŒæ­¥ä¸Šä¼ æ–‡ä»¶ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
    import requests
    from requests_toolbelt.multipart.encoder import MultipartEncoder

    try:
        # è·å–æ–‡ä»¶åï¼ˆå¸¦æ‰©å±•åï¼‰
        filename = os.path.basename(final_file)
        print(f"\n[çº¿ç¨‹æ± ] å¼€å§‹ä¸Šä¼ è§†é¢‘: {filename}")
        print(f"[çº¿ç¨‹æ± ] åŸå§‹æ ‡é¢˜: {title or 'N/A'}")

        # ä¸ºäº†é¿å…Windowsä¸Šçš„ç¼–ç é—®é¢˜ï¼Œä½¿ç”¨ASCIIå®‰å…¨çš„æ–‡ä»¶åä¸Šä¼ 
        # å®é™…çš„æ ‡é¢˜é€šè¿‡titleå­—æ®µä¼ é€’
        safe_filename = f"{task_id}.mp4"  # ä½¿ç”¨task_idä½œä¸ºä¸´æ—¶æ–‡ä»¶å

        with open(final_file, 'rb') as f:
            # ä½¿ç”¨MultipartEncoderï¼Œç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²å­—æ®µéƒ½æ˜¯UTF-8ç¼–ç 
            # æ³¨æ„ï¼štitleå­—æ®µéœ€è¦æ˜¾å¼ç¼–ç ä¸ºUTF-8å­—èŠ‚ä¸²ï¼Œç„¶åè§£ç 
            title_utf8 = (title or '').encode('utf-8').decode('utf-8') if title else ''

            multipart_data = MultipartEncoder(
                fields={
                    'video': (safe_filename, f, 'video/mp4'),
                    'source': 'bilibili',
                    'task_id': task_id,
                    'bvid': bvid or '',
                    'title': title_utf8,  # ä¼ é€’UTF-8ç¼–ç çš„æ ‡é¢˜
                    'original_filename': filename,  # ä¼ é€’åŸå§‹æ–‡ä»¶åä½œä¸ºå‚è€ƒ
                    'skip_analysis': 'true'
                }
            )

            response = requests.post(
                "http://localhost:3004/api/videos/upload",
                data=multipart_data,
                headers={
                    'Content-Type': multipart_data.content_type,
                    'Accept-Charset': 'utf-8'  # æ˜ç¡®å‘Šè¯‰æœåŠ¡å™¨ä½¿ç”¨UTF-8
                },
                timeout=300
            )

        if response.status_code == 200:
            result = response.json()
            print(f"[çº¿ç¨‹æ± ] ä¸Šä¼ æˆåŠŸ: {result.get('videoId', 'Unknown')}")
            download_tasks[task_id]["upload_status"] = "success"
            download_tasks[task_id]["video_id"] = result.get('videoId')
            return True
        else:
            print(f"[çº¿ç¨‹æ± ] ä¸Šä¼ å¤±è´¥ [{response.status_code}]: {response.text}")
            download_tasks[task_id]["upload_status"] = "failed"
            download_tasks[task_id]["upload_error"] = response.text
            return False

    except Exception as e:
        import traceback
        print(f"[çº¿ç¨‹æ± ] ä¸Šä¼ å¼‚å¸¸: {str(e)}\n{traceback.format_exc()}")
        download_tasks[task_id]["upload_status"] = "failed"
        download_tasks[task_id]["upload_error"] = str(e)
        return False


async def trigger_post_processing(task_id: str, download_result: dict):
    """è§¦å‘åç»­å¤„ç†æµç¨‹ - åœ¨çº¿ç¨‹æ± ä¸­å¼‚æ­¥ä¸Šä¼ """
    final_file = download_result.get("final_file")
    bvid = download_result.get("bvid")
    title = download_result.get("title")  # è·å–åŸå§‹æ ‡é¢˜

    if not final_file or not os.path.exists(final_file):
        print(f"è­¦å‘Š: æœ€ç»ˆæ–‡ä»¶ä¸å­˜åœ¨: {final_file}")
        return

    # åœ¨å…¨å±€çº¿ç¨‹æ± ä¸­æ‰§è¡Œä¸Šä¼ ï¼Œä¸é˜»å¡äº‹ä»¶å¾ªç¯
    loop = asyncio.get_running_loop()
    print(f"[å¼‚æ­¥] æäº¤ä¸Šä¼ ä»»åŠ¡åˆ°çº¿ç¨‹æ± : {task_id}")
    await loop.run_in_executor(
        upload_executor,
        upload_file_sync,
        final_file,
        task_id,
        bvid,
        title  # ä¼ é€’åŸå§‹æ ‡é¢˜
    )


@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {"message": "Bili23 Download API is running", "version": "1.0.0"}





# æç®€HTMLä»£ç†ï¼šä»…ç”¨äºåœ¨å¼¹çª—å†…ä¿æŒè·³è½¬ï¼ˆä¸ä»£ç†èµ„æºï¼‰
from fastapi import Query

ALLOWED_HOST_SUFFIX = ".bilibili.com"
ALLOWED_HOST = "bilibili.com"


def _is_allowed_bilibili_url(u: str) -> bool:
    try:
        p = urlparse(u)
        if p.scheme not in ("http", "https"):
            return False
        host = (p.hostname or "").lower()
        return host == ALLOWED_HOST or host.endswith(ALLOWED_HOST_SUFFIX)
    except Exception:
        return False


@app.get("/proxy")
async def proxy_html(request: Request, url: str = Query(None)):
    """
    æç®€ä»£ç†ï¼š
    - åªä»£ç†HTMLé¡µé¢
    - ä¸ºæ‰€æœ‰é“¾æ¥æ³¨å…¥â€œåœ¨å½“å‰çª—å£æ‰“å¼€â€çš„é€»è¾‘
    - èµ„æºï¼ˆimg/js/cssï¼‰ç›´æ¥ä»Bç«™åŸŸååŠ è½½ï¼ˆé€šè¿‡<base>ä¿®æ­£ç›¸å¯¹è·¯å¾„ï¼‰
    é™åˆ¶ï¼š
    - ç™»å½•æ€ç­‰ä¾èµ–cookieçš„åŠŸèƒ½ä¸å¯ç”¨ï¼ˆé¡µé¢æ¥æºébilibili.comï¼‰
    """
    target_url = url or "https://www.bilibili.com/"

    if not _is_allowed_bilibili_url(target_url):
        return HTMLResponse("<h3>ä»…å…è®¸è®¿é—® bilibili.com åŸŸå</h3>", status_code=400)

    headers = {
        "User-Agent": request.headers.get(
            "user-agent",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124 Safari/537.36",
        ),
        "Accept-Language": request.headers.get("accept-language", "zh-CN,zh;q=0.9"),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
    }

    async with httpx.AsyncClient(follow_redirects=True, timeout=15) as client:
        resp = await client.get(target_url, headers=headers)

    ct = resp.headers.get("content-type", "")

    # éHTMLå†…å®¹ï¼Œç›´æ¥é€ä¼ ï¼ˆä¸€èˆ¬ä¸ä¼šå‘½ä¸­ï¼Œå› ä¸ºæˆ‘ä»¬ä¸æ”¹èµ„æºURLï¼‰
    if "text/html" not in ct:
        return Response(content=resp.content, media_type=ct or "application/octet-stream")

    html = resp.text

    try:
        soup = BeautifulSoup(html, "html.parser")

        # åŸºç¡€ï¼šä¿®æ­£ç›¸å¯¹è·¯å¾„åˆ°Bç«™åŸŸï¼ˆé¿å…èµ„æºè¯·æ±‚åˆ°æœ¬åœ°åŸŸï¼‰
        p = urlparse(str(resp.url))
        base_origin = f"{p.scheme}://{p.hostname}"
        base_tag = soup.new_tag("base", href=base_origin + "/")
        if soup.head:
            soup.head.insert(0, base_tag)
        else:
            head = soup.new_tag("head")
            head.append(base_tag)
            soup.insert(0, head)

        # å°½é‡ç§»é™¤ target=_blankï¼Œå‡å°‘æ–°å¼€æ ‡ç­¾
        for a in soup.find_all("a"):
            if a.has_attr("target"):
                a["target"] = "_self"

        # æ³¨å…¥è„šæœ¬ï¼šæ‹¦æˆªæ‰€æœ‰é“¾æ¥ç‚¹å‡» & è¦†ç›– window.open
        proxy_origin = str(request.base_url).rstrip("/")
        inject_js = f"""
<script>
(function(){{
  try {{
    var PROXY_PREFIX = '{proxy_origin}/proxy?url=';
    function abs(u) {{
      var a = document.createElement('a');
      a.href = u;
      return a.href;
    }}
    // æ•è·é˜¶æ®µæ‹¦æˆªæ‰€æœ‰<a>ç‚¹å‡»
    document.addEventListener('click', function(e) {{
      var t = e.target;
      while (t && t.tagName !== 'A') t = t.parentElement;
      if (!t) return;
      var href = t.getAttribute('href');
      if (!href || href.indexOf('javascript:') === 0) return;
      // å…è®¸ä¸­é”®/æ–°çª—å£å¿«æ·é”®è‡ªè¡Œå¤„ç†
      if (e.metaKey || e.ctrlKey || e.shiftKey || e.which === 2) return;
      e.preventDefault();
      var url = abs(href);
      window.location.href = PROXY_PREFIX + encodeURIComponent(url);
    }}, true);

    // è¦†ç›– window.openï¼Œä½¿å…¶åœ¨å½“å‰çª—å£å†…å¯¼èˆª
    var _open = window.open;
    window.open = function(u, name, features) {{
      try {{
        if (u) {{
          var url = abs(u);
          window.location.href = PROXY_PREFIX + encodeURIComponent(url);
          return window;
        }}
      }} catch(_e) {{}}
      return _open.apply(this, arguments);
    }};
  }} catch(e) {{}}
}})();
</script>
"""
        if soup.body:
            soup.body.append(BeautifulSoup(inject_js, "html.parser"))
        else:
            html += inject_js
            return HTMLResponse(content=html, media_type="text/html")

        return HTMLResponse(content=str(soup), media_type="text/html")
    except Exception as e:
        # è§£æå¤±è´¥åˆ™å›é€€ï¼šç®€å•æ³¨å…¥è„šæœ¬ï¼ˆä¸æ”¹DOMï¼‰
        fallback = f"""
{html}
<script>
(function(){{
  try {{
    var PROXY_PREFIX = '{proxy_origin}/proxy?url=';
    document.addEventListener('click', function(e) {{
      var t=e.target; while(t && t.tagName!=='A') t=t.parentElement; if(!t) return;
      var href=t.getAttribute('href'); if(!href||href.indexOf('javascript:')===0) return;
      if (e.metaKey || e.ctrlKey || e.shiftKey || e.which === 2) return;
      e.preventDefault();
      var a=document.createElement('a'); a.href=href; var abs=a.href;
      window.location.href = PROXY_PREFIX + encodeURIComponent(abs);
    }}, true);
    var _open=window.open; window.open=function(u){{ try{{ if(u){{ var a=document.createElement('a'); a.href=u; var abs=a.href; window.location.href=PROXY_PREFIX+encodeURIComponent(abs); return window; }} }}catch(_e){{}} return _open.apply(this, arguments); }}
  }} catch(_e) {{}}
}})();
</script>
"""
        return HTMLResponse(content=fallback, media_type="text/html")



if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "bili_api_server:app",
        host="0.0.0.0",
        port=8888,
        reload=True
    )
